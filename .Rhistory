)
write.csv(solution, "./lottery-solution.csv", row.names = FALSE)
#ggplot() +
#  xlab("Actual Value") +
#  ylab("Predicted Probability") +
#  geom_jitter(aes(x = test_res$win, y = test_res$prob, color='Prediction'))
ggplot() +
xlab("Actual Value") +
ylab("Predicted Value") +
geom_point(aes(x = test_res$prob, y = test_res$win, color='Prediction')) +
geom_smooth(aes(method="glm", x = test_res$prob, y = test_res$win))
#ggplot() +
#  xlab("Actual Value") +
#  ylab("Predicted Probability") +
#  geom_jitter(aes(x = test_res$win, y = test_res$prob, color='Prediction'))
ggplot() +
xlab("Actual Value") +
ylab("Predicted Value") +
geom_point() +
geom_smooth(aes(method="glm", x = test_res$prob, y = test_res$win))
#ggplot() +
#  xlab("Actual Value") +
#  ylab("Predicted Probability") +
#  geom_jitter(aes(x = test_res$win, y = test_res$prob, color='Prediction'))
ggplot() +
xlab("Actual Value") +
ylab("Predicted Value") +
geom_point() +
geom_smooth(aes(method="glm", method.args = list(family="binomial") x = test_res$prob, y = test_res$win))
#ggplot() +
#  xlab("Actual Value") +
#  ylab("Predicted Probability") +
#  geom_jitter(aes(x = test_res$win, y = test_res$prob, color='Prediction'))
ggplot() +
xlab("Actual Value") +
ylab("Predicted Value") +
geom_point() +
geom_smooth(aes(method="glm", method.args = list(family="binomial") x = test_res$prob, y = test_res$win))
#ggplot() +
#  xlab("Actual Value") +
#  ylab("Predicted Probability") +
#  geom_jitter(aes(x = test_res$win, y = test_res$prob, color='Prediction'))
ggplot() +
xlab("Actual Value") +
ylab("Predicted Value") +
geom_point() +
geom_smooth(aes(method="glm", method.args = list(family="binomial") x = test_res$prob, y = test_res$round))
#ggplot() +
#  xlab("Actual Value") +
#  ylab("Predicted Probability") +
#  geom_jitter(aes(x = test_res$win, y = test_res$prob, color='Prediction'))
ggplot() +
xlab("Actual Value") +
ylab("Predicted Value") +
geom_point() +
geom_smooth(aes(method="glm", method.args = list(family="binomial"), x = test_res$prob, y = test_res$round))
#ggplot() +
#  xlab("Actual Value") +
#  ylab("Predicted Probability") +
#  geom_jitter(aes(x = test_res$win, y = test_res$prob, color='Prediction'))
ggplot() +
xlab("Actual Value") +
ylab("Predicted Value") +
geom_point() +
geom_smooth(aes(method="glm", method.args = list(family="binomial"), x = test_res$prob, y = test_res$win))
round
#ggplot() +
#  xlab("Actual Value") +
#  ylab("Predicted Probability") +
#  geom_jitter(aes(x = test_res$win, y = test_res$prob, color='Prediction'))
ggplot() +
xlab("Actual Value") +
ylab("Predicted Value") +
geom_point() +
geom_smooth(aes(method="glm", method.args = list(family="binomial"), x = test_res$prob, y = test_res$round))
#ggplot() +
#  xlab("Actual Value") +
#  ylab("Predicted Probability") +
#  geom_jitter(aes(x = test_res$win, y = test_res$prob, color='Prediction'))
ggplot(aes(x = test_res$prob, y = test_res$round)) +
xlab("Actual Value") +
ylab("Predicted Value") +
geom_point() +
geom_smooth(aes(method="glm", method.args = list(family="binomial")))
#ggplot() +
#  xlab("Actual Value") +
#  ylab("Predicted Probability") +
#  geom_jitter(aes(x = test_res$win, y = test_res$prob, color='Prediction'))
ggplot(x = test_res$prob, y = test_res$round) +
xlab("Actual Value") +
ylab("Predicted Value") +
geom_point() +
geom_smooth(aes(method="glm", method.args = list(family="binomial")))
#ggplot() +
#  xlab("Actual Value") +
#  ylab("Predicted Probability") +
#  geom_jitter(aes(x = test_res$win, y = test_res$prob, color='Prediction'))
ggplot(test_tes, aes(x = prob, y = round)) +
xlab("Actual Value") +
ylab("Predicted Value") +
geom_point() +
geom_smooth(aes(method="glm", method.args = list(family="binomial")))
#ggplot() +
#  xlab("Actual Value") +
#  ylab("Predicted Probability") +
#  geom_jitter(aes(x = test_res$win, y = test_res$prob, color='Prediction'))
ggplot(test_res, aes(x = prob, y = round)) +
xlab("Actual Value") +
ylab("Predicted Value") +
geom_point() +
geom_smooth(aes(method="glm", method.args = list(family="binomial")))
#ggplot() +
#  xlab("Actual Value") +
#  ylab("Predicted Probability") +
#  geom_jitter(aes(x = test_res$win, y = test_res$prob, color='Prediction'))
ggplot(test_res, aes(x = round, y = prob)) +
xlab("Actual Value") +
ylab("Predicted Value") +
geom_point() +
geom_smooth(aes(method="glm", method.args = list(family="binomial")))
#ggplot() +
#  xlab("Actual Value") +
#  ylab("Predicted Probability") +
#  geom_jitter(aes(x = test_res$win, y = test_res$prob, color='Prediction'))
ggplot(test_res, aes(x = round, y = prob)) +
xlab("Actual Value") +
ylab("Predicted Value") +
geom_point(colors="magenta") +
geom_smooth(aes(method="glm", method.args = list(family="binomial")))
#ggplot() +
#  xlab("Actual Value") +
#  ylab("Predicted Probability") +
#  geom_jitter(aes(x = test_res$win, y = test_res$prob, color='Prediction'))
ggplot(test_res, aes(x = round, y = prob)) +
xlab("Actual Value") +
ylab("Predicted Value") +
geom_point(color = 'magenta')) +
#ggplot() +
#  xlab("Actual Value") +
#  ylab("Predicted Probability") +
#  geom_jitter(aes(x = test_res$win, y = test_res$prob, color='Prediction'))
ggplot(test_res, aes(x = round, y = prob)) +
xlab("Actual Value") +
ylab("Predicted Value") +
geom_point(color = 'magenta') +
geom_smooth(aes(method="glm", method.args = list(family="binomial")))
#ggplot() +
#  xlab("Actual Value") +
#  ylab("Predicted Probability") +
#  geom_jitter(aes(x = test_res$win, y = test_res$prob, color='Prediction'))
ggplot(test_res, aes(x = round, y = prob)) +
xlab("Actual Value") +
ylab("Predicted Value") +
geom_point(color = 'magenta', alpha=0.5) +
geom_smooth(aes(method="glm", method.args = list(family="binomial")))
#ggplot() +
#  xlab("Actual Value") +
#  ylab("Predicted Probability") +
#  geom_jitter(aes(x = test_res$win, y = test_res$prob, color='Prediction'))
ggplot(test_res, aes(x = round, y = prob)) +
xlab("Actual Value") +
ylab("Predicted Value") +
geom_point(color = 'magenta', alpha(0.5)) +
geom_smooth(aes(method="glm", method.args = list(family="binomial")))
#ggplot() +
#  xlab("Actual Value") +
#  ylab("Predicted Probability") +
#  geom_jitter(aes(x = test_res$win, y = test_res$prob, color='Prediction'))
ggplot(test_res, aes(x = round, y = prob)) +
xlab("Actual Value") +
ylab("Predicted Value") +
geom_point(color = 'red') +
geom_smooth(aes(method="glm", method.args = list(family="binomial")))
#ggplot() +
#  xlab("Actual Value") +
#  ylab("Predicted Probability") +
#  geom_jitter(aes(x = test_res$win, y = test_res$prob, color='Prediction'))
ggplot(test_res, aes(x = round, y = prob)) +
xlab("Actual Value") +
ylab("Predicted Probability") +
geom_point(color = 'red') +
geom_smooth(aes(method="glm", method.args = list(family="binomial")))
# AI-X Final Project
# Unsupervised Learning based on TF-IDF
# Dataset: League of Legends Tribunal Chatlogs (Kaggle)
# https://www.kaggle.com/datasets/simshengxue/league-of-legends-tribunal-chatlogs
library(dplyr) # R Package: dplyr - advanced filtering and selection
library(tm) # R Package: tm - Text Mining/Merging for preprocess of TF-IDF, and TF-IDF itself
setwd("~/Desktop/Dev/HYU/2023-02/AI-X/project/gamechatban") # Change this value to your working dir.
chatlogs <- read.csv("./chatlogs.csv")
# Pre-Processing Steps; Feature Engineering Pipeline for the chatlogs.
# 1. Pruning
# Select only tuples where association_to_offender = offender.
# 2. Grammatical & Game-specific Expression Removal:
# Remove common grammatical expressions like "is" and "are" to enhance the validity of the analysis.
# 3. Feature Engineering - Severity:
# Introduce a new feature called 'severity' based on the total number of case reports.
# Total case report <= 3: Severe
# Total Case Report >= 4 && <= 6: Normal
# Total Case Report >= 7: Low
# 4. Concatenation of Chatlogs:
# Group chatlogs based on the common reported reason.
# Concatenate chatlogs within each group into a single text.
# Chatlogs will be merged into a single column for each most common reported reason, considering the newly defined 'severity' feature.
# Step 1: Pruning: Select only offender's chatlog.
chatlogs <- chatlogs %>% filter(association_to_offender == 'offender')
# Remove not-required column (association_to_offender: All columns will be offender)
chatlogs <- subset(chatlogs, select = -association_to_offender)
# Step 2: Gramatical Game-specific Expression Removal: Used gsub and REGEX to do such task.
# Read champion names
champion_names <- read.csv("./champion_names.csv")
# Create a regex pattern for both grammatical expressions and champion names/abbreviations
pattern <- paste0("\\b(?:is|are|&gt|&lt|was|were|", paste(unique(c(champion_names$Champion, champion_names$Abbreviation)), collapse = "|"), ")\\b")
# Remove both grammatical expressions and champion names/abbreviations from chatlogs$message
chatlogs$message <- gsub(pattern, "", chatlogs$message, ignore.case = TRUE)
# Export into csv for later use. (Pre-processed.csv)
write.csv(chatlogs, "processed.csv")
# Step 3:  Feature Engineering - Severity
chatlogs$severity <- cut( # Categorize numbers into factors.
chatlogs$case_total_reports,
breaks = c(-Inf, 3, 6, Inf),
labels = c("Severe", "Normal", "Low"),
include.lowest = TRUE
)
# Step 4: Concatenation of Chatlogs
concatenated <- chatlogs %>%
group_by(most_common_report_reason, severity) %>% #Group by following two category
summarise(concatenated_text = paste(message, collapse = " ")) %>%
ungroup()
write.csv(concatenated, "concat.csv")
# TF-IDF (Term-Frequency Inverse Document Frequency) Matrix Anaylsis; Process TF-IDF for each concatenated text to get 'toxiticy level of each words'.
# 1. Create a corpus for TF-IDF, pre-process it.
# 2. Create DTM for TF-IDF, and generate TF-IDF matrix
# 3. Transpose it and apply new column name to analyse the reported reason and severity.
# 4. Scale Up and round the value to get toxic level.
# 5. Export into csv. 'toxicity_lev.csv'
# Create a Corpus from the column concatenated_text.
corpus <- Corpus(VectorSource(concatenated$concatenated_text))
# Additional pre-process of the text in the corpus. (e.g. removing punctuation, stripping whitespaces, etc.)
corpus <- tm_map(corpus, content_transformer(tolower)) # Convert each contents into lower case
corpus <- tm_map(corpus, removePunctuation) # Remove Punctuations
corpus <- tm_map(corpus, removeWords, stopwords("english")) # Remove Additional English stopwords (a, the, etc) that hadn't been filtered.
corpus <- tm_map(corpus, stripWhitespace) # Strip Whitespace
# Create DTM (Document-Term Matrix) based on the corpus, which is used for TF-IDF
dtm <- DocumentTermMatrix(corpus)
# Create TF-IDF Matrix based on the DTM.
tf_idf <- weightTfIdf(dtm)
tf_idf <- t(as.matrix(tf_idf)) # Transpose
# Generate Column name
tf_idf_col_name <- paste(concatenated$most_common_report_reason, concatenated$severity, sep = "_")
# Set the column name of the transposed TF_IDF
colnames(tf_idf) <- tf_idf_col_name
# Scale up and Round the values
tf_idf <- round((tf_idf * 1000), 2)
# Convert TF-IDF matrix into a new data frame for further analysis.
tf_idf_df <- as.data.frame(tf_idf)
# Make it into csv for further analysis & supervised learning.
write.csv(tf_idf_df, "toxic_lev.csv")
# Assess Toxic level of each offender's chatlog
# Append a new column 'toxic_level' is chatlog.
chatlogs$toxic_score <- 0
# Iterate over rows in 'chatlogs'
for (i in 1:nrow(chatlogs)) {
# Get the message for the current row
message <- chatlogs$message[i]
# Split the message into terms
terms <- unlist(strsplit(message, " "))
# Find rows in 'tf_idf_df' where 'Term' matches the terms
matching_rows <- tf_idf_df[tf_idf_df$Term %in% terms, ]
# Calculate the sum of weights for each term
tlv <- sum(rowSums(matching_rows[, -1, drop = FALSE]))
# Set the weight based on severity
weight <- switch(chatlogs$severity[i], "Normal" = 0.6, "Low" = 0.3, 1)
# Assign the toxic score to the corresponding row in 'chatlogs'
chatlogs$toxic_score[i] <- tlv * weight
}
chatlogs <- subset(chatlogs, select = -severity)
write.csv(chatlogs, "offender_chatlog_with_toxic_score.csv")
View(chatlogs)
# Iterate over rows in 'chatlogs'
for (i in 1:nrow(chatlogs)) {
# Get the message for the current row
message <- chatlogs$message[i]
# Split the message into terms
terms <- unlist(strsplit(message, " "))
# Find rows in 'tf_idf_df' where 'Term' matches the terms
matching_rows <- tf_idf_df[tf_idf_df$Term %in% terms, ]
# Calculate the sum of weights for each term
tlv <- sum(rowSums(matching_rows[, -1, drop = FALSE]))
# Set the weight based on severity
weight <- switch(chatlogs$severity[i], "Normal" = 0.6, "Low" = 0.3, 1)
if (!is.finite(tlv * weight)) {
warning("Invalid value detected in toxic score calculation. Setting to 0.")
tlv <- 0
}
# Assign the toxic score to the corresponding row in 'chatlogs'
chatlogs$toxic_score[i] <- round((tlv * weight),2)
}
# Get the message for the current row
message <- chatlogs$message[i]
# Split the message into terms
terms <- unlist(strsplit(message, " "))
# Find rows in 'tf_idf_df' where 'Term' matches the terms
matching_rows <- tf_idf_df[tf_idf_df$Term %in% terms, ]
# Calculate the sum of weights for each term
tlv <- sum(rowSums(matching_rows[, -1, drop = FALSE]))
# Set the weight based on severity
weight <- switch(chatlogs$severity[i], "Normal" = 0.6, "Low" = 0.3, 1)
# Set the weight based on severity
weight <- switch(chatlogs$severity[i], "Normal" = 0.6, "Low" = 0.3, 1)
# Set the weight based on severity
weight <- ifelse(chatlogs$severity[i] == "Normal", 0.6,
ifelse(chatlogs$severity[i] == "Low", 0.3, 1))
# Iterate over rows in 'chatlogs'
for (i in 1:nrow(chatlogs)) {
# Get the message for the current row
message <- chatlogs$message[i]
# Split the message into terms
terms <- unlist(strsplit(message, " "))
# Find rows in 'tf_idf_df' where 'Term' matches the terms
matching_rows <- tf_idf_df[tf_idf_df$Term %in% terms, ]
# Calculate the sum of weights for each term
tlv <- sum(rowSums(matching_rows[, -1, drop = FALSE]))
# Set the weight based on severity
weight <- ifelse(chatlogs$severity[i] == "Normal", 0.6,
ifelse(chatlogs$severity[i] == "Low", 0.3, 1))
# Assign the toxic score to the corresponding row in 'chatlogs'
chatlogs$toxic_score[i] <- round((tlv * weight),2)
}
# Set the weight based on severity
weight <- ifelse(chatlogs$severity[i] == "Normal", 0.6,
ifelse(chatlogs$severity[i] == "Low", 0.3, 1))
# Get the message for the current row
message <- chatlogs$message[i]
# Split the message into terms
terms <- unlist(strsplit(message, " "))
# Find rows in 'tf_idf_df' where 'Term' matches the terms
matching_rows <- tf_idf_df[tf_idf_df$Term %in% terms, ]
View(matching_rows)
View(tf_idf_df)
tlv <- 0 # Toxic Level for current chatlog
message <- chatlogs$message[i]
terms <- unlist(strsplit(message, " "))
for (term in terms) {
row_idx <- which(rownames(tf_idf_df) == term)
if(!identical(row_idx, integer(0))){
weight_row <- tf_idf_df[row_idx, , drop = FALSE]
tlv <- tlv + rowSums(weight_row) # Add Weight
}
}
# Apply Weight based on severity.
weight <- switch(chatlogs$severity[i], "Normal" = 0.6, "Low" = 0.3, 1)
chatlogs$toxic_score[i] <- round((tlv * weight), 2)
for (term in terms) {
row_idx <- which(rownames(tf_idf_df) == term)
if(!identical(row_idx, integer(0))){
weight_row <- tf_idf_df[row_idx, , drop = FALSE]
tlv <- tlv + rowSums(weight_row) # Add Weight
}
}
tlv <- 0 # Toxic Level for current chatlog
message <- chatlogs$message[i]
terms <- unlist(strsplit(message, " "))
for (term in terms) {
row_idx <- which(rownames(tf_idf_df) == term)
if(!identical(row_idx, integer(0))){
weight_row <- tf_idf_df[row_idx, , drop = FALSE]
tlv <- tlv + rowSums(weight_row) # Add Weight
}
}
# Apply Weight based on severity.
weight <- ifelse(chatlogs$severity[i] == "Normal", 0.6,
ifelse(chatlogs$severity[i] == "Low", 0.3, 1))
# Apply Weight based on severity.
print(chatlogs$severity[i])
# AI-X Final Project
# Unsupervised Learning based on TF-IDF
# Dataset: League of Legends Tribunal Chatlogs (Kaggle)
# https://www.kaggle.com/datasets/simshengxue/league-of-legends-tribunal-chatlogs
library(dplyr) # R Package: dplyr - advanced filtering and selection
library(tm) # R Package: tm - Text Mining/Merging for preprocess of TF-IDF, and TF-IDF itself
setwd("~/Desktop/Dev/HYU/2023-02/AI-X/project/gamechatban") # Change this value to your working dir.
chatlogs <- read.csv("./chatlogs.csv")
# Pre-Processing Steps; Feature Engineering Pipeline for the chatlogs.
# 1. Pruning
# Select only tuples where association_to_offender = offender.
# 2. Grammatical & Game-specific Expression Removal:
# Remove common grammatical expressions like "is" and "are" to enhance the validity of the analysis.
# 3. Feature Engineering - Severity:
# Introduce a new feature called 'severity' based on the total number of case reports.
# Total case report <= 3: Severe
# Total Case Report >= 4 && <= 6: Normal
# Total Case Report >= 7: Low
# 4. Concatenation of Chatlogs:
# Group chatlogs based on the common reported reason.
# Concatenate chatlogs within each group into a single text.
# Chatlogs will be merged into a single column for each most common reported reason, considering the newly defined 'severity' feature.
# Step 1: Pruning: Select only offender's chatlog.
chatlogs <- chatlogs %>% filter(association_to_offender == 'offender')
# Remove not-required column (association_to_offender: All columns will be offender)
chatlogs <- subset(chatlogs, select = -association_to_offender)
# Step 2: Gramatical Game-specific Expression Removal: Used gsub and REGEX to do such task.
# Read champion names
champion_names <- read.csv("./champion_names.csv")
# Create a regex pattern for both grammatical expressions and champion names/abbreviations
pattern <- paste0("\\b(?:is|are|&gt|&lt|was|were|", paste(unique(c(champion_names$Champion, champion_names$Abbreviation)), collapse = "|"), ")\\b")
# Remove both grammatical expressions and champion names/abbreviations from chatlogs$message
chatlogs$message <- gsub(pattern, "", chatlogs$message, ignore.case = TRUE)
# Export into csv for later use. (Pre-processed.csv)
write.csv(chatlogs, "processed.csv")
# Step 3:  Feature Engineering - Severity
chatlogs$severity <- cut( # Categorize numbers into factors.
chatlogs$case_total_reports,
breaks = c(-Inf, 3, 6, Inf),
labels = c("Severe", "Normal", "Low"),
include.lowest = TRUE
)
# Step 4: Concatenation of Chatlogs
concatenated <- chatlogs %>%
group_by(most_common_report_reason, severity) %>% #Group by following two category
summarise(concatenated_text = paste(message, collapse = " ")) %>%
ungroup()
write.csv(concatenated, "concat.csv")
# TF-IDF (Term-Frequency Inverse Document Frequency) Matrix Anaylsis; Process TF-IDF for each concatenated text to get 'toxiticy level of each words'.
# 1. Create a corpus for TF-IDF, pre-process it.
# 2. Create DTM for TF-IDF, and generate TF-IDF matrix
# 3. Transpose it and apply new column name to analyse the reported reason and severity.
# 4. Scale Up and round the value to get toxic level.
# 5. Export into csv. 'toxicity_lev.csv'
# Create a Corpus from the column concatenated_text.
corpus <- Corpus(VectorSource(concatenated$concatenated_text))
# Additional pre-process of the text in the corpus. (e.g. removing punctuation, stripping whitespaces, etc.)
corpus <- tm_map(corpus, content_transformer(tolower)) # Convert each contents into lower case
corpus <- tm_map(corpus, removePunctuation) # Remove Punctuations
corpus <- tm_map(corpus, removeWords, stopwords("english")) # Remove Additional English stopwords (a, the, etc) that hadn't been filtered.
corpus <- tm_map(corpus, stripWhitespace) # Strip Whitespace
# Create DTM (Document-Term Matrix) based on the corpus, which is used for TF-IDF
dtm <- DocumentTermMatrix(corpus)
# Create TF-IDF Matrix based on the DTM.
tf_idf <- weightTfIdf(dtm)
tf_idf <- t(as.matrix(tf_idf)) # Transpose
# Generate Column name
tf_idf_col_name <- paste(concatenated$most_common_report_reason, concatenated$severity, sep = "_")
# Set the column name of the transposed TF_IDF
colnames(tf_idf) <- tf_idf_col_name
# Scale up and Round the values
tf_idf <- round((tf_idf * 1000), 2)
# Convert TF-IDF matrix into a new data frame for further analysis.
tf_idf_df <- as.data.frame(tf_idf)
# Make it into csv for further analysis & supervised learning.
write.csv(tf_idf_df, "toxic_lev.csv")
# Assess Toxic level of each offender's chatlog
# Append a new column 'toxic_level' is chatlog.
chatlogs$toxic_score <- 0
for(i in 1:nrow(chatlogs)) {
tlv <- 0 # Toxic Level for current chatlog
message <- chatlogs$message[i]
terms <- unlist(strsplit(message, " "))
for (term in terms) {
row_idx <- which(rownames(tf_idf_df) == term)
if(!identical(row_idx, integer(0))){
weight_row <- tf_idf_df[row_idx, , drop = FALSE]
tlv <- tlv + rowSums(weight_row) # Add Weight
}
}
# Apply Weight based on severity.
print(chatlogs$severity[i])
weight <- ifelse(chatlogs$severity[i] == "Normal", 0.6,
ifelse(chatlogs$severity[i] == "Low", 0.3, 1))
chatlogs$toxic_score[i] <- round((tlv * weight), 2)
}
for(i in 1:nrow(chatlogs)) {
# Get the message for the current row
message <- chatlogs$message[i]
# Split the message into terms
terms <- unlist(strsplit(message, " "))
# Find rows in 'tf_idf_df' where 'Term' matches the terms
matching_rows <- tf_idf_df[tf_idf_df$Term %in% terms, ]
# Calculate the sum of weights for each term
tlv <- sum(rowSums(matching_rows[, -1, drop = FALSE]))
# Set the weight based on severity
weight <- ifelse(chatlogs$severity[i] == "Normal", 0.6,
ifelse(chatlogs$severity[i] == "Low", 0.3, 1))
chatlogs$toxic_score[i] <- round((tlv * weight), 2)
}
res_log <- subset(chatlogs, select = X, message, most_common_report_reason, toxic_score)
res_log <- chatlogs[ , c(X, message, most_common_report_reason, toxic_score)]
res_log <- chatlogs[ , c(message, most_common_report_reason, toxic_score)]
res_log <- chatlogs[X, message, most_common_report_reason, toxic_score]
res_log <- chatlogs[X, message, most_common_report_reason, toxic_score]
head(chatlogs)
res_log <- chatlogs[, c("X", "message", "most_common_report_reason", "toxic_score")]
View(res_log)
for(i in 1:nrow(chatlogs)) {
tlv <- 0 # Toxic Level for current chatlog
message <- chatlogs$message[i]
terms <- unlist(strsplit(message, " "))
for (term in terms) {
row_idx <- which(rownames(tf_idf_df) == term)
if(!identical(row_idx, integer(0))){
weight_row <- tf_idf_df[row_idx, , drop = FALSE]
tlv <- tlv + rowSums(weight_row) # Add Weight
}
}
# Apply Weight based on severity.
weight <- ifelse(chatlogs$severity[i] == "Normal", 0.6,
ifelse(chatlogs$severity[i] == "Low", 0.3, 1))
chatlogs$toxic_score[i] <- round((tlv * weight), 2)
}
res_log <- chatlogs[, c("X", "message", "most_common_report_reason", "toxic_score")]
write.csv(res_log, "offender_chatlog_with_toxic_score.csv")
View(res_log)
